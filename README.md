# X Vibe Replying

A Chrome extension that boosts your Twitter engagement by highlighting strategic replies using a local LLM via Ollama.
## Demo

https://github.com/user-attachments/assets/a9d7aaa3-b5ee-4678-9936-30b0d0d7159b


## ğŸš€ Quick Start

1. **Backend**
   ```bash
   cd server
   python3 -m venv venv && source venv/bin/activate
   pip install -r requirements.txt
   cp .env.example .env
   # Edit `.env` to set your Ollama server URL & model
   python app.py
   ```
2. **Extension**
   - Open `chrome://extensions` in Chrome
   - Enable Developer Mode
   - Load unpacked â†’ select the `extension/` folder

## ğŸ”§ Features

- **Age Filter**: Hide or mark tweets older than X hours.
- **LLM Evaluation**: Green check or red X marks strategic vs. non-strategic replies.
- **Customizable**: Adjust filter hours, tweet actions, core prompt, and toggle evaluation.

## âš™ï¸ Configuration

- **.env** (in `server/`):
  ```
  OLLAMA_URL=http://localhost:11434
  OLLAMA_MODEL=qwen3
  ```
- **Popup Settings**: Filter hours, actions for old/bad tweets, custom prompt (must include `{tweet}`), enable/disable evaluation.

## ğŸ¤” Troubleshooting

- **Server Errors**: Ensure Flask (`python app.py`) is running on the correct port.
- **Ollama Issues**: Verify Ollama server & model are accessible (`ollama list`).
- **Extension**: Reload in Chrome, inspect console for errors.

## ğŸ—‚ï¸ Project Structure

```
.
â”œâ”€â”€ extension/                # Chrome extension files
â”‚   â”œâ”€â”€ background.js         # Handles communication with the server
â”‚   â”œâ”€â”€ content.js            # Interacts with Twitter/X pages
â”‚   â”œâ”€â”€ popup.html            # Popup UI
â”‚   â”œâ”€â”€ popup.js              # Popup logic
â”‚   â”œâ”€â”€ popup.css             # Popup styling
â”‚   â”œâ”€â”€ manifest.json         # Extension manifest
â”‚   â””â”€â”€ images/               # Icons and badges
â”œâ”€â”€ server/                   # Backend Flask server
â”‚   â”œâ”€â”€ app.py                # Flask application logic
â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies
â”‚   â””â”€â”€ .env                  # Environment variables (Ollama URL, Model)
â””â”€â”€ README.md                 # This file
```

## ğŸ’¡ Tips

- Don't set the age filter below **3 hours**; hiding too many tweets may trigger rate limits or cause Twitter to block your feed.
- Craft your custom prompt to fit your needs: include example tweets and replies that have worked for you.
- Limit yourself to **20 replies per hour** to avoid appearing spammy and risking temporary bans.

## â“ FAQ

**Q: Why did you make this?**
A: I made it for myself to improve the rate at which I can reply to grow a following without spending so much time on Twitter.

**Q: Why are the suggestions for recommended tweets so bad?**
A: You really have to customize the prompt to get it to work effectively; larger qwen models or other open source models also prove to work better on a case-by-case basis.

**Q: Why Ollama?**
A: I'm cheap and I can run models for free.
